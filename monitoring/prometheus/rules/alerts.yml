# Правила алертов для Prometheus

groups:
  # Алерты для сервисов
  - name: services
    interval: 30s
    rules:
      # Сервис недоступен
      - alert: ServiceDown
        expr: up{job=~"api-gateway|mark-service|integration-service|notification-service"} == 0
        for: 1m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: 'Сервис {{ $labels.job }} недоступен'
          description: 'Сервис {{ $labels.job }} на {{ $labels.instance }} недоступен более 1 минуты'
          runbook_url: 'https://docs.znak-lavki.com/runbooks/service-down'

      # Высокая частота ошибок
      - alert: HighErrorRate
        expr: |
          (
            sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
            /
            sum(rate(http_requests_total[5m])) by (service)
          ) > 0.05
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: 'Высокая частота ошибок в {{ $labels.service }}'
          description: 'Сервис {{ $labels.service }} возвращает более 5% ошибок 5xx за последние 5 минут'

      # Медленные ответы
      - alert: HighResponseTime
        expr: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
          ) > 1
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: 'Медленные ответы в {{ $labels.service }}'
          description: '95 перцентиль времени ответа {{ $labels.service }} превышает 1 секунду'

  # Алерты для инфраструктуры
  - name: infrastructure
    interval: 30s
    rules:
      # Высокое использование CPU
      - alert: HighCPUUsage
        expr: |
          100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 10m
        labels:
          severity: warning
          team: devops
        annotations:
          summary: 'Высокое использование CPU на {{ $labels.instance }}'
          description: 'CPU usage на {{ $labels.instance }} превышает 80% более 10 минут'

      # Высокое использование памяти
      - alert: HighMemoryUsage
        expr: |
          (
            node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes
          ) / node_memory_MemTotal_bytes * 100 > 85
        for: 10m
        labels:
          severity: warning
          team: devops
        annotations:
          summary: 'Высокое использование памяти на {{ $labels.instance }}'
          description: 'Memory usage на {{ $labels.instance }} превышает 85%'

      # Мало свободного места на диске
      - alert: LowDiskSpace
        expr: |
          (
            node_filesystem_avail_bytes{mountpoint="/",fstype!="rootfs"}
            / node_filesystem_size_bytes{mountpoint="/",fstype!="rootfs"}
          ) * 100 < 15
        for: 5m
        labels:
          severity: critical
          team: devops
        annotations:
          summary: 'Мало свободного места на {{ $labels.instance }}'
          description: 'На {{ $labels.instance }} осталось менее 15% свободного места'

  # Алерты для PostgreSQL
  - name: postgres
    interval: 30s
    rules:
      # PostgreSQL недоступен
      - alert: PostgresDown
        expr: pg_up == 0
        for: 1m
        labels:
          severity: critical
          team: database
        annotations:
          summary: 'PostgreSQL недоступен'
          description: 'PostgreSQL на {{ $labels.instance }} недоступен более 1 минуты'

      # Много активных соединений
      - alert: PostgresHighConnections
        expr: |
          sum(pg_stat_activity_count) by (instance)
          /
          sum(pg_settings_max_connections) by (instance)
          * 100 > 80
        for: 5m
        labels:
          severity: warning
          team: database
        annotations:
          summary: 'Много активных соединений PostgreSQL'
          description: 'PostgreSQL на {{ $labels.instance }} использует более 80% доступных соединений'

      # Медленные запросы
      - alert: PostgresSlowQueries
        expr: pg_stat_statements_mean_time_seconds{query!~"^(COMMIT|ROLLBACK|BEGIN)"} > 1
        for: 5m
        labels:
          severity: warning
          team: database
        annotations:
          summary: 'Медленные запросы в PostgreSQL'
          description: 'Обнаружены запросы выполняющиеся более 1 секунды'

      # Репликация отстает
      - alert: PostgresReplicationLag
        expr: pg_replication_lag > 30
        for: 5m
        labels:
          severity: warning
          team: database
        annotations:
          summary: 'Репликация PostgreSQL отстает'
          description: 'Репликация отстает более чем на 30 секунд'

  # Алерты для Redis
  - name: redis
    interval: 30s
    rules:
      # Redis недоступен
      - alert: RedisDown
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: 'Redis недоступен'
          description: 'Redis на {{ $labels.instance }} недоступен более 1 минуты'

      # Высокое использование памяти Redis
      - alert: RedisHighMemoryUsage
        expr: |
          redis_memory_used_bytes / redis_memory_max_bytes * 100 > 90
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: 'Высокое использование памяти Redis'
          description: 'Redis на {{ $labels.instance }} использует более 90% доступной памяти'

      # Много отклоненных соединений
      - alert: RedisRejectedConnections
        expr: increase(redis_rejected_connections_total[5m]) > 0
        labels:
          severity: warning
          team: backend
        annotations:
          summary: 'Redis отклоняет соединения'
          description: 'Redis на {{ $labels.instance }} отклонил {{ $value }} соединений за последние 5 минут'

  # Алерты для Kubernetes
  - name: kubernetes
    interval: 30s
    rules:
      # Pod в состоянии CrashLoopBackOff
      - alert: PodCrashLooping
        expr: |
          rate(kube_pod_container_status_restarts_total[15m]) > 0
        for: 5m
        labels:
          severity: critical
          team: devops
        annotations:
          summary: 'Pod {{ $labels.namespace }}/{{ $labels.pod }} в CrashLoopBackOff'
          description: 'Pod {{ $labels.namespace }}/{{ $labels.pod }} перезапускается'

      # Pod не может запуститься
      - alert: PodNotReady
        expr: |
          sum by (namespace, pod) (
            kube_pod_status_phase{phase=~"Pending|Unknown"}
          ) > 0
        for: 15m
        labels:
          severity: warning
          team: devops
        annotations:
          summary: 'Pod {{ $labels.namespace }}/{{ $labels.pod }} не готов'
          description: 'Pod {{ $labels.namespace }}/{{ $labels.pod }} не может запуститься более 15 минут'

      # Deployment имеет недоступные реплики
      - alert: DeploymentReplicasMismatch
        expr: |
          kube_deployment_spec_replicas != kube_deployment_status_replicas_available
        for: 10m
        labels:
          severity: warning
          team: devops
        annotations:
          summary: 'Deployment {{ $labels.namespace }}/{{ $labels.deployment }} имеет недоступные реплики'
          description: 'Deployment {{ $labels.namespace }}/{{ $labels.deployment }}: {{ $value }} реплик недоступны'

      # Node не готов
      - alert: KubernetesNodeNotReady
        expr: kube_node_status_condition{condition="Ready",status="true"} == 0
        for: 5m
        labels:
          severity: critical
          team: devops
        annotations:
          summary: 'Kubernetes node {{ $labels.node }} не готов'
          description: 'Node {{ $labels.node }} находится в состоянии NotReady более 5 минут'

      # Высокое использование CPU на node
      - alert: KubernetesNodeHighCPU
        expr: |
          (sum(rate(container_cpu_usage_seconds_total[5m])) by (node)
          /
          sum(machine_cpu_cores) by (node)) * 100 > 80
        for: 15m
        labels:
          severity: warning
          team: devops
        annotations:
          summary: 'Высокое использование CPU на node {{ $labels.node }}'
          description: 'Node {{ $labels.node }} использует более 80% CPU'

  # Бизнес-метрики
  - name: business
    interval: 1m
    rules:
      # Низкая активность генерации QR кодов
      - alert: LowQRCodeGeneration
        expr: |
          rate(qr_codes_generated_total[1h]) < 1
        for: 2h
        labels:
          severity: info
          team: product
        annotations:
          summary: 'Низкая активность генерации QR кодов'
          description: 'Генерируется менее 1 QR кода в час последние 2 часа'

      # Высокая частота невалидных QR кодов
      - alert: HighInvalidQRCodes
        expr: |
          (
            rate(qr_codes_validation_failed_total[5m])
            /
            rate(qr_codes_validated_total[5m])
          ) * 100 > 10
        for: 10m
        labels:
          severity: warning
          team: product
        annotations:
          summary: 'Высокая частота невалидных QR кодов'
          description: 'Более 10% QR кодов не проходят валидацию'

      # Высокий IDR (Invalid Data Rate)
      - alert: HighIDR
        expr: |
          idr_rate{time_window="5m"} > 0.01
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: 'Высокий IDR для {{ $labels.supplier }}'
          description: 'IDR rate превышает 1% (текущее значение: {{ $value | humanizePercentage }}) для {{ $labels.supplier }}'
          runbook_url: 'https://docs.znak-lavki.com/runbooks/high-idr'

      # Критически высокий IDR
      - alert: CriticalIDR
        expr: |
          idr_rate{time_window="5m"} > 0.05
        for: 2m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: 'Критический IDR для {{ $labels.supplier }}'
          description: 'IDR rate превышает 5% (текущее значение: {{ $value | humanizePercentage }}) - требуется немедленное вмешательство'

      # Ошибки генерации марок
      - alert: MarkGenerationFailure
        expr: |
          rate(mark_generation_errors_total[5m]) > 10
        for: 5m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: 'Высокая частота ошибок генерации марок'
          description: 'Более 10 ошибок генерации марок в минуту для {{ $labels.supplier }} (тип: {{ $labels.error_type }})'

      # Низкая успешность валидации
      - alert: LowValidationSuccessRate
        expr: |
          (
            rate(mark_validation_success_total[10m])
            /
            (rate(mark_validation_success_total[10m]) + rate(mark_validation_failure_total[10m]))
          ) < 0.95
        for: 15m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: 'Низкая успешность валидации марок'
          description: 'Успешность валидации ниже 95% за последние 15 минут'

      # Медленная валидация
      - alert: SlowMarkValidation
        expr: |
          histogram_quantile(0.95,
            sum(rate(mark_validation_duration_ms_bucket[5m])) by (le)
          ) > 500
        for: 10m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: 'Медленная валидация марок'
          description: '95 перцентиль времени валидации превышает 500ms'

      # Много истекших марок
      - alert: HighExpiredMarksCount
        expr: |
          expired_marks_count > 1000
        for: 1h
        labels:
          severity: warning
          team: product
        annotations:
          summary: 'Большое количество истекших марок'
          description: 'Обнаружено {{ $value }} истекших марок для {{ $labels.supplier }}'

      # Низкое покрытие системы
      - alert: LowSystemCoverage
        expr: |
          system_coverage_percentage{coverage_type="suppliers"} < 70
        for: 30m
        labels:
          severity: info
          team: product
        annotations:
          summary: 'Низкое покрытие поставщиков'
          description: 'Покрытие системы составляет только {{ $value }}%'

      # Аномальный рост активных марок
      - alert: AbnormalActiveMarksGrowth
        expr: |
          (
            rate(active_marks_count[1h]) 
            / 
            active_marks_count offset 1h
          ) > 0.5
        for: 30m
        labels:
          severity: info
          team: product
        annotations:
          summary: 'Аномальный рост активных марок'
          description: 'Количество активных марок выросло более чем на 50% за час'

      # Высокая частота блокировки марок
      - alert: HighMarkBlockingRate
        expr: |
          rate(marks_blocked_total[5m]) > 5
        for: 10m
        labels:
          severity: warning
          team: product
        annotations:
          summary: 'Высокая частота блокировки марок'
          description: 'Блокируется более 5 марок в минуту - возможна атака или системная проблема'

  # Производительность и кэширование
  - name: performance
    interval: 30s
    rules:
      # Низкий hit rate кэша
      - alert: LowCacheHitRate
        expr: |
          (
            rate(cache_hits_total[5m])
            /
            (rate(cache_hits_total[5m]) + rate(cache_misses_total[5m]))
          ) < 0.7
        for: 10m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: 'Низкий hit rate кэша {{ $labels.cache_type }}'
          description: 'Cache hit rate ниже 70% (текущее: {{ $value | humanizePercentage }})'

      # Высокое использование пула соединений БД
      - alert: DatabaseConnectionPool
        expr: |
          (
            pg_stat_activity_count
            /
            pg_settings_max_connections
          ) * 100 > 80
        for: 5m
        labels:
          severity: warning
          team: database
        annotations:
          summary: 'Высокое использование пула соединений'
          description: 'Используется более 80% пула соединений БД ({{ $value }}%)'

      # Критическое использование пула соединений
      - alert: DatabaseConnectionPoolCritical
        expr: |
          (
            pg_stat_activity_count
            /
            pg_settings_max_connections
          ) * 100 > 95
        for: 2m
        labels:
          severity: critical
          team: database
        annotations:
          summary: 'Критическое использование пула соединений'
          description: 'Используется более 95% пула соединений БД - риск отказа в обслуживании'

      # Высокая нагрузка на HTTP endpoints
      - alert: HighEndpointLoad
        expr: |
          rate(http_requests_total[5m]) > 1000
        for: 5m
        labels:
          severity: info
          team: devops
        annotations:
          summary: 'Высокая нагрузка на endpoint {{ $labels.endpoint }}'
          description: 'Endpoint обрабатывает более 1000 запросов в минуту'
